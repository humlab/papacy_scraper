{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analysis - CO-OCCURRENCE\n",
    "### <span style='color: green'>SETUP </span> Prepare and Setup Notebook <span style='float: right; color: red'>MANDATORY</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n[autoreload of text_analytic_tools.domain.tCoIR.treaty_state failed: Traceback (most recent call last):\n  File \"/home/roger/.local/share/virtualenvs/text_analytic_tools-LUuJUi2x/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n    superreload(m, reload, self.old_objects)\n  File \"/home/roger/.local/share/virtualenvs/text_analytic_tools-LUuJUi2x/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 450, in superreload\n    update_generic(old_obj, new_obj)\n  File \"/home/roger/.local/share/virtualenvs/text_analytic_tools-LUuJUi2x/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 387, in update_generic\n    update(a, b)\n  File \"/home/roger/.local/share/virtualenvs/text_analytic_tools-LUuJUi2x/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 357, in update_class\n    update_instances(old, new)\n  File \"/home/roger/.local/share/virtualenvs/text_analytic_tools-LUuJUi2x/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 315, in update_instances\n    if hasattr(obj, 'items') or (hasattr(obj, '__contains__')\n  File \"/home/roger/.local/share/virtualenvs/text_analytic_tools-LUuJUi2x/lib/python3.7/site-packages/beakerx/runtime.py\", line 683, in __getattr__\n    return self.get(name)\n  File \"/home/roger/.local/share/virtualenvs/text_analytic_tools-LUuJUi2x/lib/python3.7/site-packages/beakerx/runtime.py\", line 510, in get\n    result = autotranslation_get(var)\n  File \"/home/roger/.local/share/virtualenvs/text_analytic_tools-LUuJUi2x/lib/python3.7/site-packages/beakerx/runtime.py\", line 705, in autotranslation_get\n    port = os.environ[\"BEAKERX_AUTOTRANSLATION_PORT\"]\n  File \"/home/roger/.local/share/virtualenvs/text_analytic_tools-LUuJUi2x/lib/python3.7/os.py\", line 679, in __getitem__\n    raise KeyError(key) from None\nKeyError: 'BEAKERX_AUTOTRANSLATION_PORT'\n]\n"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from beakerx.object import beakerx\n",
    "from beakerx import *\n",
    "\n",
    "from IPython.display import display #, set_matplotlib_formats\n",
    "import text_analytic_tools.utility as utility\n",
    "\n",
    "utility.setup_default_pd_display(pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green'>PREPARE </span> HAL Co-Windows Ratio (CWR)<span style='float: right; color: red'>MANDATORY</span>\n",
    "\n",
    "Term \"HAL\" co-occurrence frequencies is calculated in accordance with Hyperspace Analogue to Language (Lund; Burgess, 1996) vector-space model. The computation is specified in detail in section 3.1 in (Chen; Lu, 2011).\n",
    "\n",
    "\\begin{aligned}\n",
    "nw(x) &= \\text{number of sliding windows that contains term $x$} \\\\\n",
    "nw(x, y) &= \\text{number of sliding windows that contains $x$ and $y$} \\\\\n",
    "\\\\\n",
    "f(x, y) &= \\text{normalized version of nw(x, y)} \\\\\n",
    "CWR(x, y) &= \\frac{nw(x, y)}{nw(x) + nw(y) - nw(x, y)}\\\\\n",
    "\\end{aligned}\n",
    "\n",
    "- Chen Z.; Lu Y., \"A Word Co-occurrence Matrix Based Method for Relevance Feedback\"\n",
    "- Lund, K.; Burgess, C. & Atchley, R. A. (1995). \"Semantic and associative priming in high-dimensional semantic space\".[Link](https://books.google.de/books?id=CSU_Mj07G7UC).\n",
    "- Lund, K.; Burgess, C. (1996). \"Producing high-dimensional semantic spaces from lexical co-occurrence\". doi:10.3758/bf03204766 [Link](https://dx.doi.org/10.3758%2Fbf03204766).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color: green'>PREPARE </span> Compute Using Prepared Tokenized Corpus <span style='float: right; color: red'>MANDATORY</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import ipywidgets\n",
    "import text_analytic_tools.text_analysis.co_occurrence as co_occurrence\n",
    "import text_analytic_tools.common.text_corpus as text_corpus\n",
    "from text_analytic_tools.domain_logic_config import current_domain as domain_logic\n",
    "\n",
    "def compute_co_occurrence(filepath, window_size=5, distance_metric=0, method='HAL', normalize='size'):\n",
    "\n",
    "    corpus = text_corpus.SimplePreparedTextCorpus(filepath, lowercase=True)\n",
    "    document_index = domain_logic.compile_documents(corpus)\n",
    "\n",
    "    df = co_occurrence.compute(corpus, document_index, window_size, distance_metric, normalize, method)\n",
    "\n",
    "    result_filename = '{}_{}_result_co_occurrence_{}.xlsx'\\\n",
    "        .format(method, window_size, time.strftime(\"%Y%m%d_%H%M\"))\n",
    "    df.to_excel(result_filename)\n",
    "    print('Result saved to file {}'.format(result_filename))\n",
    "    print('Now you are ready to do some serious stuff!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a016fe26b948b2b4be0e4ebbc1ae13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "VBox(children=(HBox(children=(VBox(children=(Dropdown(description='Corpus', layout=Layout(width='400px'), optiâ€¦"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ui = co_occurrence.PreparedCorpusUI(domain_logic.DATA_FOLDER)\n",
    "display(ui.build(compute_co_occurrence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "2019-10-26 08:19:12,488 : INFO : Initializing dictionary\n2019-10-26 08:19:12,490 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n2019-10-26 08:19:12,533 : INFO : built Dictionary(2067 unique tokens: ['AND', 'AT', 'Affairs', 'Alfredo', 'Article']...) from 10 documents (total 18111 corpus positions)\n2019-10-26 08:19:12,627 : INFO : Builiding vocabulary...\n2019-10-26 08:19:12,630 : INFO : Vocabulary of size 1708 built.\n2019-10-26 08:19:12,633 : INFO : Year 1950...\n2019-10-26 08:19:12,853 : INFO : Year 1951...\n2019-10-26 08:19:12,936 : INFO : Year 1952...\n2019-10-26 08:19:13,374 : INFO : Year 1953...\n2019-10-26 08:19:13,446 : INFO : Year 1954...\n2019-10-26 08:19:13,518 : INFO : Year 1955...\n2019-10-26 08:19:13,589 : INFO : Year 1956...\n2019-10-26 08:19:13,662 : INFO : Year 1957...\n2019-10-26 08:19:13,850 : INFO : Year 1958...\n2019-10-26 08:19:14,232 : INFO : Year 1959...\n2019-10-26 08:19:14,303 : INFO : Year 1960...\n2019-10-26 08:19:14,742 : INFO : Year 1961...\n2019-10-26 08:19:15,382 : INFO : Year 1962...\n2019-10-26 08:19:15,453 : INFO : Year 1963...\n2019-10-26 08:19:15,523 : INFO : Year 1964...\n2019-10-26 08:19:15,983 : INFO : Year 1965...\n2019-10-26 08:19:16,213 : INFO : Year 1966...\n2019-10-26 08:19:16,531 : INFO : Year 1967...\nResult saved to file HAL_5_result_co_occurrence_20191026_0819.xlsx\nNow you are ready to do some serious stuff!\n"
    }
   ],
   "source": [
    "filepath = '/home/roger/source/text_analytic_tools/data/tCoIR/sample_corpus.txt_preprocessed.zip'\n",
    "compute_co_occurrence(filepath, window_size=5, distance_metric=0, method='HAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/roger/source/text_analytic_tools/data/tCoIR/'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_logic.DATA_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}