{"cells":[{"cell_type":"markdown","metadata":{},"source":["## tCoIR - Text Analysis\n","### <span style='color: green'>SETUP </span> Prepare and Setup Notebook <span style='float: right; color: red'>MANDATORY</span>"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"}],"source":["%load_ext autoreload\n","%autoreload 2\n","\n","from beakerx.object import beakerx\n","from beakerx import *\n","\n","from IPython.display import display #, set_matplotlib_formats\n","import text_analytic_tools.utility as utility\n","\n","utility.setup_default_pd_display(pd)\n"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["steps: Raw text corpus => Prepped text corpus => textaCy corpus => filtered & tokenized corpus => word co-occurrence\n","\n","Load (or create a new) textaCy corpus from the source text files."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","container = textacy_utility.load_or_create(\n","    source_path='/home/roger/source/text_analytic_tools/data/tCoIR/tCoIR_en_45-72.txt.zip',\n","    language='en',\n","    document_index=None,\n","    merge_entities=False,\n","    overwrite=False,\n","    use_compression=True,\n","    disabled_pipes=tuple((\"ner\", \"parser\", \"textcat\"))\n",")\n","\n","corpus = current_corpus_container().textacy_corpus\n","corpus_path = current_corpus_container().prepped_source_path\n"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["Prepare a filtered tokenized corpus."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","docs = ((doc._.meta['filename'], doc) for doc in corpus)\n","tokenized_docs = textacy_utility.extract_document_tokens(docs, **opts)\n","pos_tags = domain_logic.pos_tags()\n","document_index = domain_logic.document_index(corpus)\n","\n","filepath, df_summary = common.store_tokenized_corpus_as_archive(\n","    tokenized_docs,\n","    corpus_source_filepath,\n","    term_substitutions=term_substitutions(corpus),\n","    min_freq=gui.min_freq.value,\n","    max_doc_freq=gui.max_doc_freq.value,\n","    substitute_terms=gui.substitute_terms.value,\n","    ngrams=gui.ngrams.value,\n","    min_word=gui.min_word.value,\n","    normalize=gui.normalize.value,\n","    filter_stops=gui.filter_stops.value,\n","    filter_punct=gui.filter_punct.value,\n","    named_entities=gui.named_entities.value,\n","    include_pos=gui.include_pos.value,\n","    chunk_size=gui.chunk_size.value,\n","    word_counts=word_counts,\n","    word_document_counts=word_document_counts\n",")\n","\n","logger.info(\"Done! Result stored in '{}'\".format(filepath))\n","\n","display(df_summary)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["import time\n","import text_analytic_tools.text_analysis.co_occurrence as co_occurrence\n","import text_analytic_tools.common.text_corpus as text_corpus\n","\n","from text_analytic_tools.domain_logic_config import current_domain as domain_logic\n","\n","def compute_co_occurrence(filepath, window_size=5, distance_metric=0, method='HAL', normalize='size'):\n","\n","    corpus = text_corpus.SimplePreparedTextCorpus(filepath, lowercase=True)\n","    document_index = domain_logic.compile_documents(corpus)\n","\n","    df = co_occurrence.compute(corpus, document_index, window_size, distance_metric, normalize, method)\n","\n","    result_filename = '{}_{}_result_co_occurrence_{}.xlsx'.format(method, window_size, time.strftime(\"%Y%m%d_%H%M\"))\n","    df.to_excel(result_filename)\n","    print('Result saved to file {}'.format(result_filename))\n","    print('Now you are ready to do some serious stuff!')\n"]},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":["https://github.com/maciejkula/glove-python/issues/96\n","\n","```bash\n","% git clone https://github.com/maciejkula/glove-python.git\n","% cd glove-python/\n","% cd glove/\n","% cython glove_cython.pyx\n","% cythonize glove_cython.pyx\n","% cython metrics/accuracy_cython.pyx\n","% cythonize metrics/accuracy_cython.pyx\n","% cython --cplus corpus_cython.pyx\n","% cythonize corpus_cython.pyx\n","% cd ..\n","% python setup.py cythonize\n","% make\n","% pip install -e .\n","```\n","\n","  "]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}