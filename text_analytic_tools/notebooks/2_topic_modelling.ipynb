{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Text Analysis - Topic Modelling\n","### <span style='color: green'>SETUP </span> Prepare and Setup Notebook <span style='float: right; color: red'>MANDATORY</span>"]},{"cell_type":"code","execution_count":null,"metadata":{"code_folding":[]},"outputs":[],"source":"# Setup\n%load_ext autoreload\n%autoreload 2\n\nimport sys, os, collections, zipfile\nimport re, typing.re\nimport warnings\nimport nltk, textacy, spacy \nimport pickle\nimport pandas as pd\nimport ipywidgets as widgets\nimport bokeh, bokeh.plotting, bokeh.models, matplotlib.pyplot as plt\nimport text_analytic_tools.utility as utility\nimport text_analytic_tools.utility.widgets as widgets\nimport text_analytic_tools.common.text_corpus as text_corpus\nimport text_analytic_tools.common.textacy_utility as textacy_utility\nimport text_analytic_tools.text_analysis.topic_model as topic_model\nimport text_analytic_tools.text_analysis.topic_model_utility as topic_model_utility\n\nfrom beakerx.object import beakerx\nfrom beakerx import *\nfrom IPython.display import display, set_matplotlib_formats\n\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \nwarnings.filterwarnings(\"ignore\", category=UserWarning) \nlogger = utility.getLogger('corpus_text_analysis')\n\nutility.setup_default_pd_display(pd)\n\nfrom text_analytic_tools.domain_logic_config import current_domain as domain_logic\n\n%matplotlib inline\n\n# set_matplotlib_formats('svg')   \nbokeh.plotting.output_notebook()\n\ncurrent_corpus_container = lambda: textacy_utility.CorpusContainer.container()\ncurrent_corpus           = lambda: textacy_utility.CorpusContainer.corpus()\ncurrent_state            = lambda: topic_model_utility.TopicModelContainer.singleton()\ncurrent_data             = lambda: current_state().data\ncurrent_topic_model      = lambda: current_state().topic_model\n"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"%%bash\n#mkdir ./tmp\n#ln -s /home/roger/source/STTM ./lib"},{"cell_type":"markdown","metadata":{},"source":["## <span style='color: green;'>MODEL</span> Compute Topic Model Based on Raw Source Text Corpus<span style='color: red; float: right'>ALTERNATIVE #1</span>\n","\n","#### <span style='color: green'>PREPARE</span> Load (or Create) The Corpus <span style='float: right; color: red'>OPTIONAL</span>\n","Setup a new corpus from the raw source text files the reside in a zip archive. This step uses the spaCy and textaCy frameworks for PoS tagging. This will take some time, several minutes, For large text files. If the same processing and filtering rules are repeatedly, then it is recommended to prepare the corpus once and for all using \"1_extract_corpus_text\" (also see next step).\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"import textacy_corpus_utility as textacy_utility\nimport textacy_corpus_gui\n\ntry:\n    container = current_corpus_container()\n    textacy_corpus_gui.display_corpus_load_gui(domain_logic.DATA_FOLDER, document_index=None, container=container)\nexcept Exception as ex:\n    raise\n    logger.error(ex)"},{"cell_type":"markdown","metadata":{},"source":["#### <span style='color: green;'>MODEL</span> Compute the Topic Model<span style='color: red; float: right'>OPTIONAL</span>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"import topic_model_gui\n\ntry:\n    gui = topic_model_gui.TextacyCorpusUserInterface(\n        data_folder=domain_logic.DATA_FOLDER,\n        state=current_state(),\n        document_index=domain_logic.compile_documents(current_corpus()),\n        tagset=domain_logic.get_tagset(),\n        substitution_filename=domain_logic.SUBSTITUTION_FILENAME\n    )\n    gui.display(current_corpus())\n    \nexcept Exception as ex:\n    raise\n    logger.error(ex)"},{"cell_type":"markdown","metadata":{},"source":["## <span style='color: green'>MODEL </span> Compute Topic Model Based on a Previously Prepared Text Corpus <span style='float: right; color: red'>ALTERNATIVE #2</span>\n","This step loads a text corpus consisting of pre-processed tokens. This is much faster compered to previous step since the corpus is assumed to be tokenized, lemmatized and filtered, and the corpus can be used by the topic modelling engines without further processing.  \n","\n","- Use the **1_extract_corpus_text** notebook to prepare this kind of corpus.\n","- This is recommended for large corpora when the pre-process take a long and if the same filters and setup are to be used several times.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false},"outputs":[],"source":"import topic_model_gui\n\ntry:\n    \n    def fn_doc_index(corpus):\n        return domain_logic.compile_documents_by_filename(corpus.filenames)\n    \n    gui = topic_model_gui.PreparedCorpusUserInterface(data_folder=DATA_FOLDER, state=current_state(), fn_doc_index=fn_doc_index)\n    \n    gui.display(None)\n    \nexcept Exception as ex:\n    raise\n    logger.error(ex)"},{"cell_type":"markdown","metadata":{},"source":["## <span style='color: green;'>MODEL</span> Store the Current Model or Load a Previously Computed Topic Model<span style='color: red; float: right'>OPTIONAL</span>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"import pickle\nimport glob\nimport topic_model\nimport topic_model_utility\n\ndef get_persisted_model_paths():\n    return sorted([ x for x in glob.glob(os.path.join(DATA_FOLDER, '*.pickle')) ])\n\ndef get_store_filename(identifier):\n    filename = os.path.join(DATA_FOLDER, 'topic_model.pickle')\n    filename = utility.path_add_date(filename)\n    filename = utility.path_add_suffix(filename, identifier)\n    return filename\n    \ndef display_persist_topic_model_gui(state):\n    \n    gui = types.SimpleNamespace(\n        stored_path=widgets.Dropdown(description='Path', options=get_persisted_model_paths(), layout=widgets.Layout(width='40%')),\n        load=widgets.Button(description='Load', button_style='Success', layout=widgets.Layout(width='80px')),\n        store=widgets.Button(description='Store', button_style='Success', layout=widgets.Layout(width='80px')),\n        identifier=widgets.Text(description='Identifier', layout=widgets.Layout(width='300px')),\n        output=widgets.Output()\n    )\n    \n    boxes = widgets.VBox([\n        widgets.HBox([gui.stored_path, gui.load, gui.store, gui.identifier ]),\n        widgets.HBox([\n            widgets.Label(value=\"\", layout=widgets.Layout(width='40%')),\n            widgets.Label(value=\"Stored models will be named ./data/topic_model_yyyymmdd_$identifier$.pickle\", layout=widgets.Layout(width='40%')),\n        ]),\n        widgets.VBox([gui.output])\n    ])\n    \n    def load_handler(*args):\n        \n        with gui.output:\n            \n            if gui.stored_path.value is None:\n                print(\"Please specify which model to load.\")\n                return\n\n            state.data = topic_model.load_model(gui.stored_path.value)\n\n            topics = topic_model_utility.get_lda_topics(state.topic_model, n_tokens=20)\n\n            display(topics)\n\n    def store_handler(*args):\n        \n        gui.output.clear_output()\n\n        with gui.output:\n\n            if gui.identifier.value == '':\n                print(\"Please specify a unique identifier for the model.\")\n                return\n\n            if gui.identifier.value != utility.filename_whitelist(gui.identifier.value):\n                print(\"Please use ONLY valid filename characters in identifier.\")\n                return\n\n            filename = get_store_filename(gui.identifier.value)\n\n            topic_model.store_model(state.data, filename)\n\n            gui.stored_path.options = get_persisted_model_paths()\n            gui.stored_path.value = filename if filename in gui.stored_path.options else None\n\n            print('Model stored in file {}'.format(filename))\n            \n    gui.load.on_click(load_handler)\n    gui.store.on_click(store_handler)\n    \n    display(boxes)\n\ndisplay_persist_topic_model_gui(current_state())\n"},{"cell_type":"markdown","metadata":{},"source":["## <span style='color: green;'>VISUALIZE</span> Display Topic's Word Distribution as a Wordcloud<span style='color: red; float: right'>TRY IT</span>"]},{"cell_type":"code","execution_count":null,"metadata":{"code_folding":[]},"outputs":[],"source":"# Display LDA topic's token wordcloud\nopts = { 'max_font_size': 100, 'background_color': 'white', 'width': 900, 'height': 600 }\nimport wordcloud\nimport matplotlib.pyplot as plt\n\ndef plot_wordcloud(df, token='token', weight='weight', figsize=(14, 14/1.618), **args):\n    token_weights = dict({ tuple(x) for x in df[[token, weight]].values })\n    image = wordcloud.WordCloud(**args,)\n    image.fit_words(token_weights)\n    plt.figure(figsize=figsize) #, dpi=100)\n    plt.imshow(image, interpolation='bilinear')\n    plt.axis(\"off\")\n    plt.show()\n    \ndef display_wordcloud(\n    state,\n    topic_id=0,\n    n_words=100,\n    output_format='Wordcloud',\n    gui=None\n):\n    def tick(n=None):\n        gui.progress.value = (gui.progress.value + 1) if n is None else n\n        \n    if gui.n_topics != state.num_topics:\n        gui.n_topics = state.num_topics\n        gui.topic_id.value = 0\n        gui.topic_id.max=state.num_topics - 1\n        \n    tick(1)\n    \n    try:\n        topic_token_weights = state.processed.topic_token_weights\n\n        df = topic_token_weights.loc[(topic_token_weights.topic_id == topic_id)]\n\n        tokens = topic_model_utility.get_topic_title(topic_token_weights, topic_id, n_tokens=n_words)\n        gui.text.value = 'ID {}: {}'.format(topic_id, tokens)\n\n        tick()\n\n        if output_format == 'Wordcloud':\n            plot_wordcloud(df, 'token', 'weight', max_words=n_words, **opts)\n        else:\n            tick()\n            df = topic_model_utility.get_topic_tokens(topic_token_weights, topic_id=topic_id, n_words=n_words)\n            tick()\n            display(df)\n    except IndexError:\n        print('No data for topic')\n    tick(0)\n    \ndef display_wordcloud_gui(state):\n    \n    output_options = ['Wordcloud', 'Table']\n    text_id = 'tx02'\n    \n    gui = widgets_utility.WidgetUtility(\n        n_topics=state.num_topics,\n        text_id=text_id,\n        text=widgets_config.text(text_id),\n        topic_id=widgets.IntSlider(description='Topic ID', min=0, max=state.num_topics - 1, step=1, value=0, continuous_update=False),\n        word_count=widgets.IntSlider(description='#Words', min=5, max=250, step=1, value=25, continuous_update=False),\n        output_format=widgets.Dropdown(description='Format', options=output_options, value=output_options[0], layout=widgets.Layout(width=\"200px\")),\n        progress=widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"95%\"))\n    )\n\n    gui.prev_topic_id = gui.create_prev_id_button('topic_id', state.num_topics)\n    gui.next_topic_id = gui.create_next_id_button('topic_id', state.num_topics)\n\n    iw = widgets.interactive(\n        display_wordcloud,\n        state=widgets.fixed(state),\n        topic_id=gui.topic_id,\n        n_words=gui.word_count,\n        output_format=gui.output_format,\n        gui=widgets.fixed(gui)\n    )\n\n    display(widgets.VBox([\n        gui.text,\n        widgets.HBox([gui.prev_topic_id, gui.next_topic_id, gui.topic_id, gui.word_count, gui.output_format]),\n        gui.progress,\n        iw.children[-1]\n    ]))\n\n    iw.update()\n\ntry:\n    display_wordcloud_gui(current_state())\nexcept topic_model_utility.TopicModelException as ex:\n    logger.info(ex)\n"},{"cell_type":"markdown","metadata":{},"source":["## <span style='color: green'>EXPLORE </span> pyLDAvis <span style='float: right; color: red'>TRY IT</span>\n","http://www.aclweb.org/anthology/W14-3110 presented at the 2014 ACL Workshop on Interactive Language Learning, Visualization, and Interfaces in Baltimore on June 27, 2014.\n","https://github.com/bmabey/pyLDAvis"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"import pyLDAvis, pyLDAvis.gensim, pyLDAvis.sklearn\nimport gensim\npyLDAvis.enable_notebook()\ndef display_pyLDAvis(state):\n    \n    try:\n        if isinstance(state.data.topic_model, textacy.tm.topic_model.TopicModel):\n            topic_model = state.data.topic_model.model\n        elif isinstance(state.data.topic_model, gensim.models.wrappers.LdaMallet):\n            topic_model = topic_model_utility.malletmodel2ldamodel(state.data.topic_model)\n        else:\n            topic_model = state.data.topic_model\n\n        if 'sklearn' in str(type(topic_model)):\n            p = pyLDAvis.sklearn.prepare(topic_model, state.data.bow_corpus, state.data.id2term)\n        else:\n            p = pyLDAvis.gensim.prepare(topic_model, state.data.bow_corpus, state.data.id2term)\n\n        display(p)\n    except Exception as ex:\n        logger.warning('This model cannot be visualized with pyLDAvis')\n        logger.error(ex)\n        \ndisplay_pyLDAvis(current_state())\n"},{"cell_type":"markdown","metadata":{},"source":["## <span style='color: green;'>VISUALIZE</span> Display Topic's Word Distribution as a Chart<span style='color: red; float: right'>TRY IT</span>\n","\n","FIXME: Number of topics as specified in compute is not relevant for all topics. state.num_topics is to high for these models wich gives an error.*\n"]},{"cell_type":"code","execution_count":null,"metadata":{"code_folding":[3]},"outputs":[],"source":"# Display topic's word distribution\nimport numpy as np\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n\ndef plot_topic_word_distribution(tokens, **args):\n\n    source = bokeh.models.ColumnDataSource(tokens)\n\n    p = bokeh.plotting.figure(toolbar_location=\"right\", **args)\n\n    cr = p.circle(x='xs', y='ys', source=source)\n\n    label_style = dict(level='overlay', text_font_size='8pt', angle=np.pi/6.0)\n\n    text_aligns = ['left', 'right']\n    for i in [0, 1]:\n        label_source = bokeh.models.ColumnDataSource(tokens.iloc[i::2])\n        labels = bokeh.models.LabelSet(x='xs', y='ys', text_align=text_aligns[i], text='token', text_baseline='middle',\n                          y_offset=5*(1 if i == 0 else -1),\n                          x_offset=5*(1 if i == 0 else -1),\n                          source=label_source, **label_style)\n        p.add_layout(labels)\n\n    p.xaxis[0].axis_label = 'Token #'\n    p.yaxis[0].axis_label = 'Probability%'\n    p.ygrid.grid_line_color = None\n    p.xgrid.grid_line_color = None\n    p.axis.axis_line_color = None\n    p.axis.major_tick_line_color = None\n    p.axis.major_label_text_font_size = \"6pt\"\n    p.axis.major_label_standoff = 0\n    return p\n\ndef display_topic_tokens(state, topic_id=0, n_words=100, output_format='Chart', gui=None):\n    \n    def tick(n=None):\n        gui.progress.value = (gui.progress.value + 1) if n is None else n\n        \n    if gui.n_topics != state.num_topics:\n        gui.n_topics = state.num_topics\n        gui.topic_id.value = 0\n        gui.topic_id.max=state.num_topics - 1\n        \n    tick(1)\n    \n    tokens = topic_model_utility.get_topic_tokens(state.processed.topic_token_weights, topic_id=topic_id, n_tokens=n_words).\\\n        copy()\\\n        .drop('topic_id', axis=1)\\\n        .assign(weight=lambda x: 100.0 * x.weight)\\\n        .sort_values('weight', axis=0, ascending=False)\\\n        .reset_index()\\\n        .head(n_words)\n    \n    if output_format == 'Chart':\n        tick()\n        tokens = tokens.assign(xs=tokens.index, ys=tokens.weight)\n        p = plot_topic_word_distribution(tokens, plot_width=1200, plot_height=500, title='', tools='box_zoom,wheel_zoom,pan,reset')\n        bokeh.plotting.show(p)\n        tick()\n    else:\n        display(tokens)\n        \n    tick(0)\n    \ndef display_topic_distribution_gui(state):\n    \n    text_id = 'wc01'\n    output_options = ['Chart', 'Table']\n    \n    gui = widgets_utility.WidgetUtility(\n        n_topics=state.num_topics,\n        text_id=text_id,\n        text=widgets_config.text(text_id),\n        topic_id=widgets.IntSlider(description='Topic ID', min=0, max=state.num_topics - 1, step=1, value=0),\n        n_words=widgets.IntSlider(description='#Words', min=5, max=500, step=1, value=75),\n        output_format=widgets.Dropdown(description='Format', options=output_options, value=output_options[0], layout=widgets.Layout(width=\"200px\")),\n        progress=widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"95%\"))\n    )\n\n    gui.prev_topic_id = gui.create_prev_id_button('topic_id', state.num_topics)\n    gui.next_topic_id = gui.create_next_id_button('topic_id', state.num_topics)\n\n    iw = widgets.interactive(\n        display_topic_tokens,\n        state=widgets.fixed(state),\n        topic_id=gui.topic_id,\n        n_words=gui.n_words,\n        output_format=gui.output_format,\n        gui=widgets.fixed(gui)\n    )\n\n    display(widgets.VBox([\n        gui.text,\n        widgets.HBox([gui.prev_topic_id, gui.next_topic_id, gui.topic_id, gui.n_words, gui.output_format]),\n        gui.progress,\n        iw.children[-1]\n    ]))\n\n    iw.update()\n\ntry:\n    display_topic_distribution_gui(current_state())\nexcept Exception as ex:\n    logger.error(ex)\n    \n"},{"cell_type":"markdown","metadata":{},"source":["## <span style='color: green;'>VISUALIZE</span> Display Topic's Trend Over Time or Documents<span style='color: red; float: right'>TRY IT</span>\n","- Displays topic's share over documents.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"code_folding":[],"scrolled":false},"outputs":[],"source":"# Plot a topic's yearly weight over time in selected LDA topic model\nimport math\n\ndef plot_topic_trend(df, category_column, value_column, x_label=None, y_label=None, **figopts):\n    \n    xs = df[category_column].astype(np.str)\n    ys = df[value_column]\n    \n    figopts = utility.extend(dict(title='', toolbar_location=\"right\"), figopts)\n    \n    p = bokeh.plotting.figure(**figopts)\n\n    glyph = p.vbar(x=xs, top=ys, width=0.5, fill_color=\"#b3de69\")\n    \n    p.xaxis.major_label_orientation = math.pi/4\n    p.xgrid.grid_line_color = None\n    p.xaxis[0].axis_label = (x_label or category_column.title().replace('_', ' ')).title()\n    p.yaxis[0].axis_label = (y_label or value_column.title().replace('_', ' ')).title()\n    p.y_range.start = 0.0\n    p.x_range.range_padding = 0.01\n    \n    return p\n\ndef display_topic_trend(\n    state,\n    topic_id,\n    year,\n    year_aggregate,\n    threshold=0.01,\n    output_format='Chart',\n    topic_changed=utility.noop\n):\n    figopts = dict(plot_width=1000, plot_height=700, title='', toolbar_location=\"right\")\n    \n    document_topic_weights = state.processed.document_topic_weights\n\n    topic_changed(topic_id)\n    \n    # FIXME VARYING ASPECT: name 'signed_year'\n    year_column = 'year'\n    \n    pivot_column = year_column if year is None else None\n    value_column = year_aggregate if year is None else 'weight'\n\n    df = document_topic_weights[(document_topic_weights.topic_id == topic_id)]\n    # FIXME MISSING YEAR IN FILENAME HACK\n    df = df[(df[year_column] > 0)]\n    \n    if year is not None:\n        # FIXME VARYING ASPECT: name 'signed_year'\n        df = df[(df[year_column] == year)]\n        \n    df = df[(df.weight > threshold)].reset_index()\n    \n    if len(df) == 0:\n        print('NO DATA')\n        return\n    \n    if year is None:\n        \n        min_year, max_year = df[year_column].min(), df[year_column].max()\n        figopts['x_range'] = list(map(str, range(min_year, max_year+1))) # utility.complete_value_range(df[category_column].unique(), str)\n        \n        df = df.groupby([year_column, 'topic_id']).agg([np.mean, np.max])['weight'].reset_index()\n        df.columns = [year_column, 'topic_id', 'mean', 'max']\n        category_column = year_column\n\n    else:\n        # FIXME: Varying ASPECTS\n        category_column = 'document_name'\n        df[category_column] = df.filename # df.treaty_id + ' ' + df.party1 + ' ' + df.party2\n        figopts['x_range'] = df[category_column].unique()\n        \n    if output_format == 'Table':\n        display(df)\n    else:\n        p = plot_topic_trend(df, category_column, value_column, **figopts)\n        bokeh.plotting.show(p)\n\ndef display_topic_trend_gui(state):\n    \n    year_low, year_high = int(state.processed.year_period[0]), int(state.processed.year_period[1])\n    year_options = [ ('all years', None) ] + [ (str(x), x) for x in range(year_low, year_high + 1)]\n    \n    text_id = 'topic_share_plot'\n    \n    gui = widgets_utility.WidgetUtility(\n        n_topics=state.num_topics,\n        text_id=text_id,\n        text=widgets_config.text(text_id),\n        year=widgets.Dropdown(description='Year', options=year_options, value=None),\n        year_aggregate=widgets.Dropdown(description='Aggregate', options=['mean', 'max'], value='max', layout=widgets.Layout(width=\"160px\")),\n        threshold=widgets.FloatSlider(description='Threshold', min=0.0, max=0.25, step=0.01, value=0.10, continuous_update=False),\n        topic_id=widgets.IntSlider(description='Topic ID', min=0, max=state.num_topics - 1, step=1, value=0, continuous_update=False),\n        output_format=widgets.Dropdown(description='Format', options=['Chart', 'Table'], value='Chart', layout=widgets.Layout(width=\"160px\")),\n        progress=widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"340px\")),\n    )\n    \n    gui.prev_topic_id = gui.create_prev_id_button('topic_id', state.num_topics)\n    gui.next_topic_id = gui.create_next_id_button('topic_id', state.num_topics)\n    \n    def on_topic_changed(topic_id):\n        try:\n            if gui.n_topics != state.num_topics:\n                gui.n_topics = state.num_topics\n                gui.topic_id.value = 0\n                gui.topic_id.max = state.num_topics - 1\n\n            tokens = topic_model_utility.get_topic_title(state.processed.topic_token_weights, topic_id, n_tokens=200)\n            gui.text.value = 'ID {}: {}'.format(topic_id, tokens)\n        except:\n            gui.text.value = 'ID {}: NO DATA'.format(topic_id)\n            \n    iw = widgets.interactive(\n        display_topic_trend,\n        state=widgets.fixed(state),\n        topic_id=gui.topic_id,\n        year=gui.year,\n        year_aggregate=gui.year_aggregate,\n        threshold=gui.threshold,\n        output_format=gui.output_format,\n        topic_changed=widgets.fixed(on_topic_changed)\n    )\n\n    display(widgets.VBox([\n        gui.text,\n        widgets.HBox([gui.prev_topic_id, gui.next_topic_id, gui.year, gui.year_aggregate, gui.output_format]),\n        widgets.HBox([gui.topic_id, gui.threshold, gui.progress]),\n        iw.children[-1]\n    ]))\n    \n    iw.update()\n\ntry:\n    display_topic_trend_gui(current_state())\nexcept Exception as ex:\n    logger.error(ex)"},{"cell_type":"markdown","metadata":{},"source":["## <span style='color: green;'>VISUALIZE</span> Display Topic to Document Network<span style='color: red; float: right'>TRY IT</span>\n","The green nodes are documents, and blue nodes are topics. The edges (lines) indicates the strength of a topic in the connected document. The width of the edge is proportinal to the strength of the connection. Note that only edges with a strength above the certain threshold are displayed."]},{"cell_type":"code","execution_count":null,"metadata":{"code_folding":[]},"outputs":[],"source":"# Visualize year-to-topic network by means of topic-document-weights\nfrom common.plot_utility import layout_algorithms, PlotNetworkUtility\nimport domain_logic_vatican as domain_logic\nimport gui_utility\nfrom common.network_utility import NetworkUtility, DISTANCE_METRICS, NetworkMetricHelper\n\ndef plot_document_topic_network(network, layout, scale=1.0, titles=None):\n    tools = \"pan,wheel_zoom,box_zoom,reset,hover,previewsave\"\n    year_nodes, topic_nodes = NetworkUtility.get_bipartite_node_set(network, bipartite=0)  \n    \n    year_source = NetworkUtility.get_node_subset_source(network, layout, year_nodes)\n    topic_source = NetworkUtility.get_node_subset_source(network, layout, topic_nodes)\n    lines_source = NetworkUtility.get_edges_source(network, layout, scale=6.0, normalize=False)\n    \n    edges_alphas = NetworkMetricHelper.compute_alpha_vector(lines_source.data['weights'])\n    \n    lines_source.add(edges_alphas, 'alphas')\n    \n    p = bokeh.plotting.figure(plot_width=1000, plot_height=600, x_axis_type=None, y_axis_type=None, tools=tools)\n    \n    r_lines = p.multi_line(\n        'xs', 'ys', line_width='weights', alpha='alphas', color='black', source=lines_source\n    )\n    r_years = p.circle(\n        'x','y', size=40, source=year_source, color='lightgreen', level='overlay', line_width=1,alpha=1.0\n    )\n    \n    r_topics = p.circle('x','y', size=25, source=topic_source, color='skyblue', level='overlay', alpha=1.00)\n    \n    p.add_tools(bokeh.models.HoverTool(renderers=[r_topics], tooltips=None, callback=widgets_utility.wf.\\\n        glyph_hover_callback(topic_source, 'node_id', text_ids=titles.index, text=titles, element_id='nx_id1'))\n    )\n\n    text_opts = dict(x='x', y='y', text='name', level='overlay', x_offset=0, y_offset=0, text_font_size='8pt')\n    \n    p.add_layout(\n        bokeh.models.LabelSet(\n            source=year_source, text_color='black', text_align='center', text_baseline='middle', **text_opts\n        )\n    )\n    p.add_layout(\n        bokeh.models.LabelSet(\n            source=topic_source, text_color='black', text_align='center', text_baseline='middle', **text_opts\n        )\n    )\n    \n    return p\n        \ndef display_document_topic_network(\n    layout_algorithm,\n    state,\n    threshold=0.10,\n    document_filters=None,\n    #parties=None,\n    #period=None,\n    ignores=None,\n    scale=1.0,\n    output_format='network',\n    document_index=None,\n    tick=utility.noop\n):\n\n    tick(1)\n    \n    corpus = current_corpus()\n    \n    corpus_docs = { x._.meta['document_id'] : x for x in gui_utility.get_documents_by_field_filters(corpus, document_index, document_filters) }\n    \n    topic_token_weights = state.processed.topic_token_weights\n    document_topic_weights = state.processed.document_topic_weights\n    \n    titles = topic_model_utility.get_topic_titles(topic_token_weights)\n\n    df = document_topic_weights[document_topic_weights.weight > threshold].reset_index()\n    \n    df = df[df.document_id.isin(list(corpus_docs.keys()))]\n    # FIXME VARYING ASPECT: filters\n    #if len(parties or []) > 0:\n    #    df = df[df.party1.isin(parties) | df.party2.isin(parties)]\n\n    #if len(period or []) == 2:\n    #    df = df[(df.signed_year>=period[0]) & (df.signed_year<=period[1])]\n        \n    if len(ignores or []) > 0:\n        df = df[~df.topic_id.isin(ignores)]\n\n    df['weight'] = utility.clamp_values(list(df.weight), (0.1, 2.0))\n\n    if len(df) == 0:\n        print('No data')\n        return\n    \n    # FIXME VARYING ASPECT: filters\n    df['title'] = df.filename # df.treaty_id + ' ' + df.party1 + ' ' + df.party2\n\n    network = NetworkUtility.create_bipartite_network(df, 'title', 'topic_id')\n    tick()\n\n    if output_format == 'network':\n        args = PlotNetworkUtility.layout_args(layout_algorithm, network, scale)\n        layout = (layout_algorithms[layout_algorithm])(network, **args)\n        tick()\n        p = plot_document_topic_network(network, layout, scale=scale, titles=titles)\n        bokeh.plotting.show(p)\n\n    elif output_format == 'table':\n        display(df)\n\n    tick(0)\n        \ndef document_topic_network_gui(document_index, state, filter_options):\n    \n    lw = lambda w: widgets.Layout(width=w)\n    \n    text_id = 'nx_id1'\n    layout_options = [ 'Circular', 'Kamada-Kawai', 'Fruchterman-Reingold']\n    #party_preset_options = wti_index.get_party_preset_options()\n    #parties_options = [ x for x in wti_index.get_countries_list() if x not in ['ALL', 'ALL OTHER'] ]\n    year_min, year_max = state.processed.year_period\n    \n    n_topics = state.num_topics\n    document_filters = gui_utility.generate_field_filters(document_index, filter_options)\n    gui = types.SimpleNamespace(\n        document_filters=document_filters,\n        #group_by_columns=widgets.Dropdown(description='Group by', value=group_by_options[0][1], options=group_by_options, layout=lw('200px')),\n        text=widgets_config.text(text_id),\n        #period=widgets.IntRangeSlider(description='Time', min=year_min, max=year_min+5, step=1, value=(year_min, year_max), continues_update=False),\n        scale=widgets.FloatSlider(description='Scale', min=0.0, max=1.0, step=0.01, value=0.1, continues_update=False),\n        threshold=widgets.FloatSlider(description='Threshold', min=0.0, max=1.0, step=0.01, value=0.50, continues_update=False),\n        output_format=widgets_utility.dropdown('Output', { 'Network': 'network', 'Table': 'table' }, 'network', layout=lw('200px')),\n        layout=widgets_utility.dropdown('Layout', layout_options, 'Fruchterman-Reingold', layout=lw('250px')),\n        #parties=widgets.SelectMultiple(description='Parties', options=parties_options, value=['FRANCE'], rows=7, layout=lw('180px')),\n        #party_preset=widgets_config.dropdown('Presets', party_preset_options, None, layout=lw('180px')),\n        progress=widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"95%\")),\n        ignores=widgets.SelectMultiple(description='Ignore', options=[('', None)] + [ ('Topic #'+str(i), i) for i in range(0, n_topics) ], value=[], rows=8, layout=lw('200px')),\n        compute=widgets.Button(description='Compute', layout=lw('120px')),\n        output=widgets.Output(layout={'border': '1px solid black'})\n    )\n    \n    def tick(x=None):\n        gui.progress.value = gui.progress.value + 1 if x is None else x\n        \n    #def on_party_preset_change(change):  # pylint: disable=W0613\n    #    if gui.party_preset.value is None:\n    #        return\n    #    gui.parties.value = gui.parties.options if 'ALL' in gui.party_preset.value else gui.party_preset.value\n            \n    #gui.party_preset.observe(on_party_preset_change, names='value')\n    \n    def compute_callback_handler(*_args):\n        gui.output.clear_output()\n        with gui.output:\n            display_document_topic_network(\n                layout_algorithm=gui.layout.value,\n                state=state,\n                threshold=gui.threshold.value,\n                #parties=gui.parties,\n                document_filters=[ (x['field'], x['widget'].value) for x in gui.document_filters],\n                #period=gui.period,\n                ignores=gui.ignores.value,\n                scale=gui.scale.value,\n                output_format=gui.output_format.value,\n                document_index=document_index,\n                tick=tick\n            )\n\n    display(widgets.VBox([\n        widgets.HBox([\n            widgets.VBox([gui.layout, gui.threshold, gui.scale ]),  # , gui.period]), \n            widgets.VBox([ x['widget'] for x in gui.document_filters]),\n            #widgets.VBox([gui.parties, gui.party_preset]), \n            widgets.VBox([gui.ignores, gui.output_format]), \n            widgets.VBox([gui.compute, gui.progress]),\n        ]),\n        gui.output,\n        gui.text,\n    ]))\n    \n    gui.compute.on_click(compute_callback_handler)\n\n    #iw.update()\n\ntry:\n    document_index = domain_logic.compile_documents(current_corpus())\n    document_topic_network_gui(\n        document_index,\n        current_state(),\n        filter_options=domain_logic.DOCUMENT_FILTERS\n    )\nexcept Exception as ex:\n    logger.error(ex)\n"},{"cell_type":"markdown","metadata":{},"source":["## <span style='color: green;'>VISUALIZE</span> Topic Trends Overview<span style='color: red; float: right'>TRY IT</span>\n","\n","- The topic shares  displayed as a scattered heatmap plot using gradient color based on topic's weight in document.\n","- [Stanford’s Termite software](http://vis.stanford.edu/papers/termite) uses a similar visualization."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":"# plot_topic_relevance_by_year\nimport bokeh.transform\n\ndef get_topic_weight_by_year_or_document(document_topic_weights, key='mean', year=None):\n    pivot_column = 'year' if year is None else 'document_id'\n    #if df[(df.year == year)]\n    df = self.get_document_topic_weights(year) \\\n        .groupby([pivot_column,'topic_id']) \\\n        .agg(config.AGGREGATES[key])[['weight']].reset_index()\n    return df, pivot_column\n    \ndef setup_glyph_coloring(df):\n    max_weight = df.weight.max()\n    #colors = list(reversed(bokeh.palettes.Greens[9]))\n    colors = ['#ffffff', '#f7fcf5', '#e5f5e0', '#c7e9c0', '#a1d99b', '#74c476', '#41ab5d', '#238b45', '#006d2c', '#00441b']\n    mapper = bokeh.models.LinearColorMapper(palette=colors, low=0.0, high=1.0) # low=df.weight.min(), high=max_weight)\n    color_transform = bokeh.transform.transform('weight', mapper)\n    color_bar = bokeh.models.ColorBar(color_mapper=mapper, location=(0, 0),\n                         ticker=bokeh.models.BasicTicker(desired_num_ticks=len(colors)),\n                         formatter=bokeh.models.PrintfTickFormatter(format=\" %5.2f\"))\n    return color_transform, color_bar\n\ndef compute_int_range_categories(values):\n    categories = values.unique()\n    if all(map(utility.isint, categories)):\n        categories = sorted(list(map(int, categories)))\n        return list(map(str, categories))\n    else:\n        return sorted(list(categories))\n\nHEATMAP_FIGOPTS = dict(title=\"Topic heatmap\", toolbar_location=\"right\",  x_axis_location=\"above\", plot_width=1000)\n\ndef plot_topic_relevance_by_year(df, xs, ys, flip_axis, titles, text_id, **figopts):\n\n    line_height = 7\n    if flip_axis is True:\n        xs, ys = ys, xs\n        line_height = 10\n\n    x_range = compute_int_range_categories(df[xs])\n    y_range = compute_int_range_categories(df[ys])\n    \n    color_transform, color_bar = setup_glyph_coloring(df)\n    \n    source = bokeh.models.ColumnDataSource(df)\n\n    if x_range is not None:\n        figopts['x_range'] = x_range\n\n    if y_range is not None:\n        figopts['y_range'] = y_range\n        figopts['plot_height'] = max(len(y_range) * line_height, 500)\n    \n    p = bokeh.plotting.figure(**figopts)\n\n    args = dict(x=xs, y=ys, source=source, alpha=1.0, hover_color='red')\n    \n    cr = p.rect(width=1, height=1, line_color=None, fill_color=color_transform, **args)\n\n    p.x_range.range_padding = 0\n    p.ygrid.grid_line_color = None\n    p.xgrid.grid_line_color = None\n    p.axis.axis_line_color = None\n    p.axis.major_tick_line_color = None\n    p.axis.major_label_text_font_size = \"8pt\"\n    p.axis.major_label_standoff = 0\n    p.xaxis.major_label_orientation = 1.0\n    p.add_layout(color_bar, 'right')\n    \n    p.add_tools(bokeh.models.HoverTool(tooltips=None, callback=widgets_utility.WidgetUtility.glyph_hover_callback(\n        source, 'topic_id', titles.index, titles, text_id), renderers=[cr]))\n    \n    return p\n\ndef display_doc_topic_heatmap(state, key='max', flip_axis=False, glyph='Circle', year=None, year_aggregate=None, output_format=None):\n    try:\n\n        titles = topic_model_utility.get_topic_titles(state.processed.topic_token_weights, n_tokens=100)\n        \n        df = state.processed.document_topic_weights.copy()\n\n        if year is not None:\n            df = df[(df.signed_year == year)]\n\n        if year is None:\n            \n            ''' Display aggregate value grouped by year  '''\n            df = df.groupby(['signed_year', 'topic_id']).agg([np.mean, np.max])['weight'].reset_index()\n            df.columns = ['signed_year', 'topic_id', 'mean', 'max']\n            df['weight'] = df[year_aggregate]\n            df['signed_year'] = df.signed_year.astype(str)\n            category_column = 'signed_year'\n            \n        else:\n            ''' Display individual treaties for selected year  '''\n            df['treaty'] = df.treaty_id + ' ' + df.party1 + ' ' + df.party2\n            df = df[['treaty', 'treaty_id', 'topic_id', 'weight']]\n            category_column = 'treaty'  \n        \n        df['document_id'] = df.index.astype(str)\n        df['topic_id'] = df.topic_id.astype(str)\n         \n        if output_format.lower() == 'heatmap':\n            \n            p = plot_topic_relevance_by_year(\n                df,\n                xs=category_column,\n                ys='topic_id',\n                flip_axis=flip_axis,\n                titles=titles,\n                text_id='topic_relevance',\n                **HEATMAP_FIGOPTS)\n\n            bokeh.plotting.show(p)\n            \n        else:\n            display(df)\n        \n    except Exception as ex:\n        raise\n        logger.error(ex)\n        \ndef doc_topic_heatmap_gui(state):\n\n    lw = lambda w: widgets.Layout(width=w)\n    \n    text_id = 'topic_relevance'\n    \n    year_min, year_max = state.processed.year_period\n    year_options = [ ('all years', None) ] + [ (x,x) for x in range(year_min, year_max + 1)]\n    \n    gui = types.SimpleNamespace(\n        text_id=text_id,\n        text=widgets_config.text(text_id),\n        flip_axis=widgets.ToggleButton(value=True, description='Flip', icon='', layout=lw(\"80px\")),\n        year=widgets.Dropdown(description='Year', options=year_options, value=None, layout=lw(\"160px\")),\n        year_aggregate=widgets.Dropdown(description='Aggregate', options=['mean', 'max'], value='max', layout=lw(\"160px\")),\n        output_format=widgets.Dropdown(description='Output', options=['Heatmap', 'Table'], value='Heatmap', layout=lw(\"180px\"))\n    )\n    \n    iw = widgets.interactive(\n        display_doc_topic_heatmap,\n        state=widgets.fixed(state),\n        flip_axis=gui.flip_axis,\n        year=gui.year,\n        year_aggregate=gui.year_aggregate,\n        output_format=gui.output_format\n    )\n\n    display(widgets.VBox([\n        widgets.HBox([gui.year, gui.year_aggregate, gui.output_format, gui.flip_axis ]),\n        widgets.HBox([iw.children[-1]]), gui.text\n    ]))\n\n    iw.update()\n\ntry:\n    doc_topic_heatmap_gui(current_state())\nexcept Exception as ex:\n    logger.error(ex)\n"},{"cell_type":"markdown","metadata":{},"source":["## <span style='color: green;'>VISUALIZE</span> Topic Cooccurrence<span style='color: red; float: right'>TRY IT</span>\n","\n","Computes weighted graph of topics co-occurring in the same document. Topics are defined as co-occurring if they both exists  in the same document both having weights above threshold. Weight are number of co-occurrences (binary yes or no). Node size reflects topic proportions over the entire corpus (normalized document) length, and are computed in accordance to how node sizes are computed in LDAvis."]},{"cell_type":"code","execution_count":null,"metadata":{"code_folding":[0],"scrolled":false},"outputs":[],"source":"# Visualize topic co-occurrence\n\nimport common.plot_utility as plot_utility\nimport common.network_utility as network_utility\nimport bokeh.plotting # import figure, show, output_notebook, output_file\n\nbokeh.plotting.output_notebook()\n\ndef get_topic_titles(topic_token_weights, topic_id=None, n_words=100):\n    df_temp = topic_token_weights if topic_id is None else topic_token_weights[(topic_token_weights.topic_id==topic_id)]\n    df = df_temp\\\n            .sort_values('weight', ascending=False)\\\n            .groupby('topic_id')\\\n            .apply(lambda x: ' '.join(x.token[:n_words].str.title()))\n    return df\n\n# FIXME: add doc token length to df_documents\ndef get_topic_proportions(corpus_documents, document_topic_weights):\n    topic_proportion = topic_model.compute_topic_proportions(document_topic_weights, corpus_documents)\n    return topic_proportion\n    \ndef display_topic_co_occurrence_network(\n    tm_data,\n    parties=None,\n    period=None,\n    ignores=None,\n    threshold=0.10,\n    layout='Fruchterman-Reingold',\n    scale=1.0,\n    output_format='table'\n):\n    try:\n        \n        model_data = tm_data.compiled_data\n        \n        titles = topic_model_utility.get_topic_titles(model_data.topic_token_weights)\n        df = model_data.document_topic_weights\n        df['document_id'] = df.index\n        \n        node_sizes = topic_model.compute_topic_proportions(df, model_data.documents)\n\n        if ignores is not None:\n            df = df[~df.topic_id.isin(ignores)]\n            \n        if len(parties or []) > 0:\n            df = df[df.party1.isin(parties) | df.party2.isin(parties)]\n            \n        if period is not None:\n            df = df[df.signed_year.between(period[0], period[1], inclusive=True)]\n            \n        df = df.loc[(df.weight >= threshold)]\n        df = pd.merge(df, df, how='inner', left_on='document_id', right_on='document_id')\n        df = df.loc[(df.topic_id_x < df.topic_id_y)]\n        df = df.groupby([df.topic_id_x, df.topic_id_y]).size().reset_index()\n        df.columns = ['source', 'target', 'weight']\n        \n        if len(df) == 0:\n            print('No data. Please change selections.')\n            return\n        \n        if output_format == 'table':\n            display(df)\n        else:\n            network = network_utility.NetworkUtility.create_network(df, source_field='source', target_field='target', weight='weight')\n            p = plot_utility.PlotNetworkUtility.plot_network(\n                network=network,\n                layout_algorithm=layout,\n                scale=scale,\n                threshold=0.0,\n                node_description=titles,\n                node_proportions=node_sizes,\n                weight_scale=10.0,\n                normalize_weights=True,\n                element_id='cooc_id',\n                figsize=(900,500)\n            )\n            bokeh.plotting.show(p)\n\n    except Exception as x:\n        raise\n        print(\"No data: please adjust filters\")\n\ndef topic_coocurrence_network_gui(wti_index, tm_data):\n    \n    lw = lambda w: widgets.Layout(width=w)\n    n_topics = tm_data.tm_model.num_topics\n    \n    model = tm_data.tm_model\n    text_id = 'cooc_id'\n    layout_options = [ 'Circular', 'Kamada-Kawai', 'Fruchterman-Reingold']\n    party_preset_options = wti_index.get_party_preset_options()\n    parties_options = [ x for x in wti_index.get_countries_list() if x != 'ALL OTHER' ]\n    year_min, year_max = tm_data.compiled_data.year_period\n    \n    gui = types.SimpleNamespace(\n        n_topics=n_topics,\n        text=widgets_utility.wf.create_text_widget(text_id),\n        period=widgets.IntRangeSlider(description='Time', min=year_min, max=year_max, step=1, value=(year_min, year_max), continues_update=False),\n        scale=widgets.FloatSlider(description='Scale', min=0.0, max=1.0, step=0.01, value=0.1, continues_update=False),\n        threshold=widgets.FloatSlider(description='Threshold', min=0.0, max=1.0, step=0.01, value=0.20, continues_update=False),\n        output_format=widgets_utility.dropdown('Output', { 'Network': 'network', 'Table': 'table' }, 'network', layout=lw('200px')),\n        layout=widgets_utility.dropdown('Layout', layout_options, 'Fruchterman-Reingold', layout=lw('250px')),\n        parties=widgets.SelectMultiple(description='Parties', options=parties_options, value=[], rows=7, layout=lw('180px')),\n        party_preset=widgets_config.dropdown('Presets', party_preset_options, None, layout=lw('180px')),\n        progress=widgets.IntProgress(min=0, max=4, step=1, value=0, layout=widgets.Layout(width=\"99%\")),\n        ignores=widgets.SelectMultiple(description='Ignore', options=[('', None)] + [ ('Topic #'+str(i), i) for i in range(0, n_topics) ], value=[], rows=8, layout=lw('180px')),\n    )\n    def tick(x=None):\n        gui.progress.value = gui.progress.value + 1 if x is None else x\n        \n    def on_party_preset_change(change):  # pylint: disable=W0613\n        if gui.party_preset.value is None:\n            return\n        gui.parties.value = gui.parties.options if 'ALL' in gui.party_preset.value else gui.party_preset.value\n            \n    gui.party_preset.observe(on_party_preset_change, names='value')\n     \n    iw = widgets.interactive(\n        display_topic_co_occurrence_network,\n        tm_data=widgets.fixed(tm_data),\n        parties=gui.parties,\n        period=gui.period,\n        ignores=gui.ignores,\n        threshold=gui.threshold,\n        layout=gui.layout,\n        scale=gui.scale,\n        output_format=gui.output_format\n    )\n    display(widgets.VBox([\n        gui.text,\n        widgets.HBox([\n            widgets.VBox([gui.layout, gui.threshold, gui.scale, gui.period]), \n            widgets.VBox([gui.parties, gui.party_preset]), \n            widgets.VBox([gui.ignores]), \n            widgets.VBox([gui.output_format, gui.progress]),\n        ]),\n        iw.children[-1]\n    ]))\n    iw.update()\n    \ntry:\n    tm_data = get_current_model()\n    topic_coocurrence_network_gui(WTI_INDEX, tm_data)\nexcept Exception as ex:\n    logger.error(ex)"},{"cell_type":"markdown","metadata":{},"source":["## <span style='color: green'>EXPLORE </span> Topic Similarity <span style='float: right; color: red'>WORK IN PROGRESS</span>\n"]},{"cell_type":"markdown","metadata":{},"source":["#### <span style='color: green'>EXPLORE </span> Topic Similarity Network<span style='float: right; color: red'>WORK IN PROGRESS</span>\n","This plot displays topic similarity based on **euclidean or cosine distances** between the **topic-to-word vectors**. Please note that the computations can take some time to exceute, especially for larger LDA models."]},{"cell_type":"code","execution_count":null,"metadata":{"code_folding":[],"scrolled":false},"outputs":[],"source":"# Visualization\nimport types\n\n# if 'zy_data' not in globals():\nzy_data = types.SimpleNamespace(\n    basename=None,\n    network=None,\n    X_n_space=None,\n    X_n_space_feature_names=None,\n    distance_matrix=None,\n    metric=None,\n    topic_proportions=None,\n    n_words = 0\n)\n\ndef plot_clustering_dendogram(clustering):\n    plt.figure(figsize=(16,6))\n    # https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.cluster.hierarchy.dendrogram.html\n    R = dendrogram(clustering)\n    plt.show()\n    plt.close()\n\ndef VectorSpaceHelper_compute_distance_matrix(X_n_space, metric='euclidean'):\n    # https://se.mathworks.com/help/stats/pdist.html\n    metric = metric.lower()\n    if metric == 'kullback–leibler': metric = VectorSpaceHelper.kullback_leibler_divergence\n    if metric == 'scipy.stats.entropy': metric = scipy.stats.entropy\n    #print(metric)\n    X = X_n_space.toarray() if hasattr(X_n_space, 'toarray') else X_n_space\n    #X_n_space += 0.00001\n    distances = distance.pdist(X, metric=metric)\n    #print(distances)\n    distance_matrix = distance.squareform(distances)\n    #print(distance_matrix)    \n    return distance_matrix\n    \ndef display_correlation_network(\n    layout_algorithm,\n    threshold=0.10,\n    scale=1.0,\n    metric='Euclidean',\n    n_words=200,\n    output_format='Network'\n):\n    global state, zy_data, zy\n\n    try:\n\n        zy.progress.value = 1\n        metric = DISTANCE_METRICS[metric]\n\n        node_description = state.get_topics_tokens_as_text()\n        node_proportions = state.get_topic_proportions()\n\n        zy.progress.value = 2\n        if zy_data.network is None or state.basename != zy_data.basename or zy_data.metric != metric or zy_data.n_words != n_words:\n\n            zy_data.basename = state.basename\n            zy_data.n_words = n_words\n            zy_data.X_n_space, zy_data.X_n_space_feature_names = state.compute_topic_terms_vector_space(n_words=n_words)\n            \n            #print(zy_data.X_n_space.shape)\n            #print(zy_data.X_n_space_feature_names)\n            zy.progress.value = 3\n            zy_data.distance_matrix = VectorSpaceHelper_compute_distance_matrix(zy_data.X_n_space, metric=metric)\n            zy_data.network = None\n\n        edges_data = VectorSpaceHelper.lower_triangle_iterator(zy_data.distance_matrix, threshold)\n\n        zy.progress.value = 4\n        if output_format == 'List':\n            df = pd.DataFrame(edges_data, columns=['x', 'y', 'weight'])\n            zy.progress.value = 5\n            display(HTML(df.to_html()))\n        else:\n            zy.progress.value = 5\n            if zy_data.network is None:\n                zy_data.network = NetworkUtility.create_network_from_xyw_list(edges_data) # zy_data.distance_matrix)\n            zy.progress.value = 6\n            p = PlotNetworkUtility.plot_network(\n                network=zy_data.network,\n                layout_algorithm=layout_algorithm,\n                scale=scale,\n                threshold=threshold,\n                node_description=node_description,\n                node_proportions=node_proportions,\n                element_id='nx_id3',\n                figsize=(1000,600)\n            )\n            zy.progress.value = 6\n            show(p)\n\n        zy.progress.value = 7\n        zy.progress.value = 0\n    except Exception as ex:\n        # logger.exception(ex)\n        print('Error: {}'.format(ex))\n        print('Empty set: please change filters')\n        zy.progress.value = 0\n\nzy = widgets_utility.WidgetUtility(\n    n_topics=state.n_topics,\n    text_id='nx_id3',\n    text=wf.create_text_widget('nx_id3'),\n    scale=wf.create_float_slider('Scale', min=0.0, max=1.0, step=0.01, value=0.1),\n    year=wf.create_int_slider(\n        description='Year', min=state.min_year, max=state.max_year, step=1, value=state.min_year\n    ),\n    n_words=wf.create_int_slider(description='#words*', min=10, max=500, step=1, value=20),\n    metric=wf.create_select_widget(label='Metric*', values=list(DISTANCE_METRICS.keys()), default='Euclidean'),\n    threshold=wf.create_float_slider('Threshold', min=0.0, max=1.0, step=0.01, value=0.01),\n    output_format=wf.create_select_widget('Format', ['Network', 'List'], default='Network'),\n    layout=wf.create_select_widget('Layout', list(layout_algorithms.keys()), default='Fruchterman-Reingold'),\n    progress=wf.create_int_progress_widget(min=0, max=7, step=1, value=0, layout=widgets.Layout(width=\"90%\"))\n) \n    \nwy = widgets.interactive(\n    display_correlation_network,\n    layout_algorithm=zy.layout,\n    threshold=zy.threshold,\n    scale=zy.scale,\n    metric=zy.metric,\n    n_words=zy.n_words,\n    output_format=zy.output_format\n)\n\ndisplay(widgets.VBox(\n    (zy.text, ) +\n    (widgets.HBox((zy.threshold,) + (zy.metric,) + (zy.output_format,)),) +\n    (widgets.HBox((zy.n_words,) + (zy.layout,) + (zy.scale,)),) +\n    (zy.progress,) +\n    (wy.children[-1],)))\n\nwy.update()\n"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}